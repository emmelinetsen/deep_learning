{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0dl0qpzOCvCgzK+2ago7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmelinetsen/deep_learning/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQdtWp4q6xgN",
        "colab_type": "text"
      },
      "source": [
        "Do MNIST classifier using numpy and python without CNN and just using plain neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OY_EjmM5Xoc",
        "colab_type": "code",
        "outputId": "037ce2a1-3079-4bb4-f873-3a8f2d44e478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rz_t3aN5vmu",
        "colab_type": "code",
        "outputId": "4fe039bd-48b3-4346-b838-3ad8a1737501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# loading the mnist data into training and testing data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# getting the first 1000 data and reshaping the dataset for the first 1000\n",
        "img, labels = (x_train[0:1000].reshape(1000,28*28) / 255), y_train[0:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WztWPz_aZLm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating an array of zeros \n",
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "\n",
        "\n",
        "# assigning 1 to where the label would be for that particular array\n",
        "# for example, if the array \n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "import sys, numpy as np\n",
        "\n",
        "test_img = x_test.reshape(len(x_test), 28*28) / 255\n",
        "test_label = np.zeros((len(y_test), 10))\n",
        "\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JgOr5mgFYqz",
        "colab_type": "code",
        "outputId": "fbab8461-7c57-4733-e57b-3698cbce9a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "relu = lambda x:(x>=0) * x # returns x if x > 0, return 0 otherwise\n",
        "relu2deriv = lambda x: x>=0 # returns 1 for input > 0, return 0 otherwise\n",
        "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        layer_0 = images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "        layer_2 = np.dot(layer_1,weights_1_2)\n",
        "\n",
        "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_2) == \\\n",
        "                                        np.argmax(labels[i:i+1]))\n",
        "\n",
        "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\\n",
        "                                    * relu2deriv(layer_1)\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    sys.stdout.write(\"\\r I:\"+str(j)+ \\\n",
        "                     \" Train-Err:\" + str(error/float(len(images)))[0:5] +\\\n",
        "                     \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I:349 Train-Err:0.108 Train-Acc:1.0"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dwl__SE5BE0",
        "colab_type": "text"
      },
      "source": [
        "a) The code should do mini batch gradient descent along with appropriate learning rate pick appropriate batch size for minibatch (read fastai and other tips and https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 for example.) see sample https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/ as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdKH_jtP5PdL",
        "colab_type": "text"
      },
      "source": [
        "b) The code should do dropout - try various dropout rates and pick the one which works well. (need not be same for all layers ;-) ). - see https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 for ideas.\n",
        "\n",
        "The code should initialize the random weights of network properly - see https://docs.google.com/presentation/d/1cYzq7TEGXRAhKF9P0eOI_q01kQAOajl-eS9h3CTGRLg/edit#slide=id.g60fb2717a6_37_196 for more information on how to initialize the random weights before training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LbX93eg9tep",
        "colab_type": "text"
      },
      "source": [
        "c) The code should do basic image augmentations to supplement the training data (not testing data) using keras libraries  (NEW than the deck) - see the image augmentations tried in https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxGBeJIh9vYK",
        "colab_type": "text"
      },
      "source": [
        "d) The code should use  3 or more layers for training (not 2 as in example ) - you have to tune and pick number of neurons in your layer and number of layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1T31Mkc92NX",
        "colab_type": "text"
      },
      "source": [
        "e) The code will continue to use relu activation layer in right places like python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wldvlZZG93oI",
        "colab_type": "text"
      },
      "source": [
        "f) The code should normalize the input as discussed in the class before training (scaling the input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my2WaAYL97N8",
        "colab_type": "text"
      },
      "source": [
        "g) The code should use appropriate learning rate (try out few to find out which one works) - you can use adaptive learning rates like different learning rates per epoch or per mini batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysWpNNCs99Du",
        "colab_type": "text"
      },
      "source": [
        "h) The code should provide appropriate metrics, visualization,  testing and training accuracy etc.,. and plot the results and confusion matrix  (this is important)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_62E4H-APu",
        "colab_type": "text"
      },
      "source": [
        "i) The code should display top common errors like in below link."
      ]
    }
  ]
}