{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/igj9fQD+J3s3YCjXdetP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5db5a9ff0a924037a37a740c87a7b2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bebdf54d734242de9d1f1aa9b46a8082",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_121b30a70de744fd8c29d7858629cf0a",
              "IPY_MODEL_b041a51cde534957a9696bc360340661"
            ]
          }
        },
        "bebdf54d734242de9d1f1aa9b46a8082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "121b30a70de744fd8c29d7858629cf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7777a9a3216742fb927907bc709ef7ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9941cd6e7483483ca1f57c6992f7d5ec"
          }
        },
        "b041a51cde534957a9696bc360340661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_912c369f8db147a6a0f6db1fa1fcfcc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 33506787.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e856a543d11d4a038e8683256942f942"
          }
        },
        "7777a9a3216742fb927907bc709ef7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9941cd6e7483483ca1f57c6992f7d5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "912c369f8db147a6a0f6db1fa1fcfcc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e856a543d11d4a038e8683256942f942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmelinetsen/deep_learning/blob/master/assignment_4/Resnet_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svWP02iGuGtF",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdniHxcVuAvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg0wkGQ6uGZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "5db5a9ff0a924037a37a740c87a7b2eb",
            "bebdf54d734242de9d1f1aa9b46a8082",
            "121b30a70de744fd8c29d7858629cf0a",
            "b041a51cde534957a9696bc360340661",
            "7777a9a3216742fb927907bc709ef7ca",
            "9941cd6e7483483ca1f57c6992f7d5ec",
            "912c369f8db147a6a0f6db1fa1fcfcc5",
            "e856a543d11d4a038e8683256942f942"
          ]
        },
        "outputId": "14a09e2d-12aa-4a6a-e2d8-b95b0c927334"
      },
      "source": [
        "# downloading CIFAR100 dataset\n",
        "# transforming the PIL Image to tensors\n",
        "train = torchvision.datasets.CIFAR100(root = \"./data\", train=True, download = True, transform = transforms.ToTensor())\n",
        "\n",
        "#loading the training data from trainset\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=4, shuffle = True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db5a9ff0a924037a37a740c87a7b2eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wanxKrMIuSdz",
        "colab_type": "text"
      },
      "source": [
        "## Resenet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY-W2tlsuQi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/resnet.py\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
        "    \"\"\"\n",
        "\n",
        "    #BasicBlock and BottleNeck block \n",
        "    #have different output size\n",
        "    #we use class attribute expansion\n",
        "    #to distinct\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        #residual function\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "        )\n",
        "\n",
        "        #shortcut\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        #the shortcut output dimension is not the same with residual function\n",
        "        #use 1*1 convolution to match the dimension\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "        \n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "        #we use a different inputsize than the original paper\n",
        "        #so conv2_x's stride is 1\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the \n",
        "        same as a neuron netowork layer, ex. conv layer), one layer may \n",
        "        contain more than one residual block \n",
        "        Args:\n",
        "            block: block type, basic block or bottle neck block\n",
        "            out_channels: output depth channel number of this layer\n",
        "            num_blocks: how many blocks per layer\n",
        "            stride: the stride of the first block of this layer\n",
        "        \n",
        "        Return:\n",
        "            return a resnet layer\n",
        "        \"\"\"\n",
        "\n",
        "        # we have num_block blocks per layer, the first block \n",
        "        # could be 1 or 2, other blocks would always be 1\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output \n",
        "\n",
        "def resnet18():\n",
        "    \"\"\" return a ResNet 18 object\n",
        "    \"\"\"\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_fZhAzNu8zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12a54dae-3f60-4dc5-deec-903a10f03665"
      },
      "source": [
        "net = resnet18()\n",
        "print(net)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv2_x): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (conv3_x): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (conv4_x): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (conv5_x): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (residual_function): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5k--xRNuZMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "1de0ea7a-07f7-40d3-c38b-123f941e80b1"
      },
      "source": [
        "# view the training data\n",
        "\n",
        "#iterating into the data\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# view the shape of 4 images\n",
        "print(images.shape) \n",
        "\n",
        "# view the shape of 1 image\n",
        "print(images[1].shape) \n",
        "\n",
        "# view the label of the first image\n",
        "print(labels[1].item())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([3, 32, 32])\n",
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksRCNaJduqkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "62673d5f-c27c-4b0d-b0a0-ddfbcd395467"
      },
      "source": [
        "#taking the first image from batch of 4 images\n",
        "\n",
        "img = images[0]\n",
        "print(type(img))\n",
        "\n",
        "#convert the tensor to numpy for displaying the image\n",
        "npimg = img.numpy()\n",
        "print(npimg.shape)\n",
        "\n",
        "#for displaying the image, shape of the image should be height * width * channels\n",
        "npimg = np.transpose(npimg, (1, 2, 0))\n",
        "print(npimg.shape)\n",
        "\n",
        "plt.figure(figsize = (2,2))\n",
        "plt.imshow(np.squeeze(npimg))\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "(3, 32, 32)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdOLrzf1uq_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3569368d-fd1d-474d-e097-d792e957147a"
      },
      "source": [
        "# Training Resnet \n",
        "\n",
        "#increase the batch size\n",
        "batch_size = 128\n",
        "\n",
        "#download the data again and set the train, test loader with different batch size\n",
        "train = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MphJT0nhuvlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1c9a9373-6d38-4541-f3db-b1979d680387"
      },
      "source": [
        "#reference a variable to gpu card to make the training faster\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ABiYnju3aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the model object and move it to GPU\n",
        "net = resnet18().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_T8EGasu4X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method to calculate the accuracy on a gpu\n",
        "def evaluate(dataloader):\n",
        "    total, correct = 0, 0\n",
        "    \n",
        "    #keeping the network in evaluation mode\n",
        "    net.eval()\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        #moving the inputs and labels to gpu\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3GJLw2uvTdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    #iterate through all the batches in each epoch\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        #keeping the network in training mode\n",
        "        net.train()\n",
        "    \n",
        "        inputs, labels = data\n",
        "        #moving the input and labels to gpu\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        #clear the gradients\n",
        "        opt.zero_grad()\n",
        "        #forward pass\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        #backward pass\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        loss_arr.append(loss.item())\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluate(testloader), evaluate(trainloader)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY_OJ2k3vT59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}